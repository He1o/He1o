---
title: 11. Conditional Random Field
date: 2022-06-06
category: Machine learning
---
<!--more-->
# 条件随机场
## 1. 历史背景
### 1.1 分类模型
我们对前面的知识进行总体的回顾。

首先，我们再次定义分类问题，在给定特定的特征向量 $\mathbf{x}=(x_1,x_2,\dots,x_K)$ 的情况下，预测单个类变量 $y$，从概率的角度来说，就是确定 $p(y|\mathbf{x})$ 的值。

最简单的方法，就是假设当类标签确定后，所有的特征都是相互独立的，也就是**条件独立性假设**，基于这种假设的分类器就是朴素贝叶斯分类器。虽然朴素贝叶斯最终计算的是 $p(y|\mathbf{x})$，但实际上是通过公式 $\displaystyle p(y|\mathbf{x})=\frac{p(y,\mathbf{x})}{p(\mathbf{x})}$ 得到的，由于分母的值都是一样的，最终 $\argmax$ 得到的结果实际上是基于以下形式的联合概率模型
$$p(y,\mathbf{x})=p(y)\prod_{k=1}^Kp(x_k|y)$$

逻辑回归则是直接拟合条件概率的函数，它的假设依据是每个类别的对数概率 $\log p(y|\mathbf{x})$ 是 $\mathbf{x}$ 的线性函数，如果再加上一个归一化常数 $Z$，就得到条件概率分布
$$p(y|\mathbf{x})=\frac{1}{Z(\mathbf{x})}\exp\left\{ {\lambda_y+\sum_{j=1}^K\lambda_{y,j}x_j}\right\}$$

其中，$Z(\mathbf{x})=\sum_y\exp\left\{ {\lambda_y+\sum_{j=1}^K\lambda_{y,j}x_j}\right\}$。从形式上来说很像是分母除以了一个 $p(\mathbf{x})$，但实际上 $Z(\mathbf{x})$ 并不是真正的 $p(\mathbf{x})$，逻辑回归并没有对 $\mathbf{x}$ 的分布构建模型。上面的公式中对每一个类别都需要一组向量进行权重表示，可以使用不同的表示法，只使用一个函数表示
$$p(y|\mathbf{x})=\frac{1}{Z(\mathbf{x})}\exp\left\{\sum_{k=1}^K\lambda_kf_k(y,\mathbf{x})\right\}$$
### 1.2 序列模型

## 2. 问题引入



## 参考
> [1. 机器学习“判定模型”和“生成模型”有什么区别？ - zhihu](https://www.zhihu.com/question/20446337/answer/2223156872)
> [2. An Introduction to Conditional Random Fields for Relational Learning](https://people.cs.umass.edu/~mccallum/papers/crf-tutorial.pdf)


> [3. Lecture notes: Hidden Markov Models](https://www.stats.ox.ac.uk/~caron/teaching/sb1b/lecturehmm.pdf)
> [4. Lecture 9: Hidden Markov Model](http://faculty.washington.edu/yenchic/18A_stat516/Lec9_HMM.pdf)
> [5. History and Theoretical Basicsof Hidden Markov Models](https://www.intechopen.com/chapters/15369)
> [6. Hidden Markov Models](https://web.stanford.edu/~jurafsky/slp3/A.pdf)